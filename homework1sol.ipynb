{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1 (100 points)\n",
    "\n",
    "The goal of this homework is to practice using [pandas](https://pypi.org/project/pandas/) methods. If your:\n",
    "\n",
    "1. code is taking a long time to run\n",
    "2. code involves for loops or while loops\n",
    "\n",
    "look through the pandas documentation for alternatives.\n",
    "\n",
    "## Exercise 1 (60 points)\n",
    "\n",
    "This exercise will use the [Titanic dataset](https://www.kaggle.com/c/titanic/data) (https://www.kaggle.com/c/titanic/data). Download the file named `train.csv` and place it in the same folder as this notebook.\n",
    "\n",
    "a) Write a function that reads in a filepath to a csv and returns the DataFrame. (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Write a function that returns the number of rows that have at least one empty column value - (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_nans(df):\n",
    "    return sum(df.apply(lambda x: sum(x.isnull().values), axis = 1)>0)\n",
    "\n",
    "print(\"there are \" +  str(num_nans(df)) + \" rows with at least one empty value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Write a function that removes all columns with more than 200 NaN values - (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_na(df):\n",
    "    for Name in df.columns:\n",
    "      t = df[Name].isnull().sum()\n",
    "      if t > 200:\n",
    "        del df[Name]    \n",
    "    return df\n",
    "\n",
    "df = drop_na(df)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) Write a function that replaces `male` with 0 and `female` with 1 - (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numerical(df):\n",
    "    df.loc[df[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "    df.loc[df[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "    return df['Sex']\n",
    "\n",
    "df['Sex'] = to_numerical(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e)  Write a function that adds four columns `First Name`, `Middle Name`, `Last Name`, and `Title` corresponding to the value in the `name` column. - (5 points) \n",
    "\n",
    "For example: `Braund, Mr. Owen Harris` would be: \n",
    "\n",
    "|First Name | Middle Name | Last Name | Title |\n",
    "|-----------|-------------|-----------|-------|\n",
    "| Owen      |  Harris     |  Braund   | Mr    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperate(x):\n",
    "    sep1 = x.split(\", \")\n",
    "    l_name = sep1[0]\n",
    "    sep2 = sep1[1].split(\". \")\n",
    "    title = sep2[0]\n",
    "    sep3 = sep2[1].split(\" \")\n",
    "    if len(sep3)==1:\n",
    "        f_name = sep3[0]\n",
    "        m_name = \"\"\n",
    "    else:\n",
    "        f_name = sep3[0]\n",
    "        m_name = sep3[1]\n",
    "    return [f_name,m_name,l_name, title]\n",
    "    \n",
    "def extract_names(df):\n",
    "    return [seperate(x) for x in df['Name']]\n",
    "\n",
    "df[['First Name', 'Middle Name', 'Last Name', 'Title']] = extract_names(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Write a function that replaces all missing ages with the average age - (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def replace_with_mean(df):\n",
    "    avg = df.Age.mean()\n",
    "    return np.round(df['Age'].fillna(avg),1)\n",
    "\n",
    "df['Age'] = replace_with_mean(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next set of questions focus on visualization. Please use pandas and [matplotlib](https://pypi.org/project/matplotlib/) for all plotting.\n",
    "\n",
    "g) Plot a bar chart of the average age of those that survived and did not survive. Briefly comment on what you observe. - (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "years_survived = df[df['Survived']==1]['Age'].mean()\n",
    "years_not_survived = df[df['Survived']==0]['Age'].mean()\n",
    "plt.bar(['survived','not survived'], [years_survived, years_not_survived],width=0.2)\n",
    "plt.ylabel(\"average age\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h) Plot a bar chart of the proportion that survived for male and female. Briefly comment on what you observe. - (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_male = len(df[df['Sex']==0])\n",
    "no_female = len(df[df['Sex']==0])\n",
    "surv_male = len(df[(df['Survived']==1)&(df['Sex']==0)])\n",
    "surv_female = len(df[(df['Survived']==1)&(df['Sex']==1)])\n",
    "not_surv_male = no_male-surv_male\n",
    "not_surv_female = no_female-surv_female\n",
    "X = ['Male','Female']\n",
    "Surv = [surv_male,surv_female]\n",
    "not_surv = [not_surv_male,not_surv_female]\n",
    "X_axis = np.arange(len(X))\n",
    "plt.bar(X_axis - 0.2, Surv, 0.4, label = 'Survived')\n",
    "plt.bar(X_axis + 0.2,not_surv, 0.4, label = 'Not survived')\n",
    "plt.xticks(X_axis, X)\n",
    "plt.ylabel(\"Percentage of people\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i) Plot a bar chart of the proportion that survived for each title. Briefly comment on what you observe. - (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = df['Title'].unique()\n",
    "surv = []\n",
    "not_surv = []\n",
    "for x in titles:\n",
    "    no_of_x=len(df[df['Title']==x])\n",
    "    no_of_surv_x=len(df[(df['Title']==x)&(df['Survived']==1)])\n",
    "    no_of_not_surv_x=no_of_x - no_of_surv_x\n",
    "    surv.append(no_of_surv_x)\n",
    "    not_surv.append(no_of_not_surv_x)\n",
    "X = titles\n",
    "X_axis = np.arange(len(X))\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.bar(X_axis - 0.2, surv, width = 0.4, label = 'survived')\n",
    "plt.bar(X_axis + 0.2, not_surv, width= 0.4, label = 'not_survived')\n",
    "plt.xticks(X_axis, X)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "j) Plot a bar chart of the average fare for those that survived and those that did not survive. Briefly comment on what you observe. - (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_survived_fare=df[df['Survived']==1]['Fare'].mean()\n",
    "ave_not_survived_fare=df[df['Survived']==0]['Fare'].mean()\n",
    "plt.bar(['survived','not survived'], [ave_survived_fare,ave_not_survived_fare],width=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k) Create a boxplot for the fare of those that survived and those that did not survive. Briefly comment on what you observe. - (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot([df[df['Survived']==1]['Fare'],df[df['Survived']==0]['Fare']],patch_artist=True,labels=['survived','Not survived'])\n",
    "plt.ylabel('the fare')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k) Create a function to subtract the mean fare from the actual fare then divide by the standard deviation - (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fare(df):\n",
    "    return (df['Fare']-df['Fare'].mean())/df['Fare'].std()\n",
    "df['Fare']=fare(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "l) Remove all non-numerical columns from the dataframe. - (2.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = df['Title'].unique()\n",
    "surv = []\n",
    "not_surv = []\n",
    "for x in titles:\n",
    "    no_of_x = len(df[df['Title']==x])\n",
    "    no_of_surv_x = len(df[(df['Title']==x)&(df['Survived']==1)])\n",
    "    no_of_not_surv_x = no_of_x - no_of_surv_x\n",
    "    surv.append(no_of_surv_x)\n",
    "    not_surv.append(no_of_not_surv_x)\n",
    "X = titles\n",
    "X_axis = np.arange(len(X))\n",
    "plt.figure(figsize = (20,10))\n",
    "plt.bar(X_axis - 0.2, surv, width = 0.4, label = 'survived')\n",
    "plt.bar(X_axis + 0.2, not_surv, width= 0.4, label = 'not_survived')\n",
    "plt.xticks(X_axis, X)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "m) Ignoring passenger ID, write a function that returns the names of the N most similar pairs of passengers using the euclidean distance? - (15 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def euclidean_distance(p1,p2):\n",
    "    sum = 0\n",
    "    for x in range(len(p1)):\n",
    "        sum += (p1[x]-p2[x])**2\n",
    "    return math.sqrt(sum)\n",
    "\n",
    "def N_most_similar_pairs(df, N):\n",
    "    df_orig = df\n",
    "    \n",
    "    df = df.drop(['Name','Ticket','Embarked','First Name','Middle Name','Last Name','Title','PassengerId'],axis=1)\n",
    "    \n",
    "    n_df = (df.values)\n",
    "    matrix = np.zeros(((df.values).shape[0],(df.values).shape[0]))\n",
    "    \n",
    "    for i in range((df.values).shape[0]):\n",
    "        for j in range((df.values).shape[0]):\n",
    "            matrix[i,j] = euclidean_distance(n_df[i],n_df[j])\n",
    "            \n",
    "    for i in range((df.values).shape[0]):\n",
    "        matrix[i,i] = math.inf\n",
    "        \n",
    "    output = []\n",
    "    for y in range(N):\n",
    "        x = np.unravel_index(np.argmin(matrix, axis=None), matrix.shape)\n",
    "        n1 = df_orig['Name'][x[0]]\n",
    "        n2 = df_orig['Name'][x[1]]\n",
    "        output.append([n1, n2])\n",
    "        matrix[x[0],x[1]] = math.inf\n",
    "    return output\n",
    "\n",
    "print(\"The 3 most similar passengers are: \" + str(N_most_similar_pairs(df, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 - (40 points)\n",
    "\n",
    "Another way to get data is by using APIs. Here we will be using the google books API (https://developers.google.com/books/docs/overview)\n",
    "\n",
    "a) Create a list with these topic strings: Python; Data Science; Data Analysis; Machine Learning; and Deep \n",
    "Learning. Use these topics, one at a time, to query the Google Books API by modifying the code below. - (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "\"\"\"\n",
    "    Google Books Api\n",
    "    See: https://developers.google.com/books/\n",
    "\"\"\"\n",
    "\n",
    "def get(topic=\"\"):\n",
    "    BASEURL = 'https://www.googleapis.com/books/v1/volumes'\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "\n",
    "    response = requests.get(BASEURL + \"?q=\" + topic, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return json.loads(response.content.decode('utf-8'))\n",
    "\n",
    "    return response\n",
    "\n",
    "topics = [\"Python\", \"Data Science\", \"Data Analysis\", \"Machine Learning\", \"Deep Learning\"]\n",
    "python = get(topics[0])\n",
    "data_science = get(topics[1])\n",
    "data_analytics = get(topics[2])\n",
    "machine_learning = get(topics[3])\n",
    "deep_learning = get(topics[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) For each returned JSON string: Convert the JSON string to a dict using `loads( )` then use this to convert it to a DataFrame: `pd.json_normalize( thedict['items'] )`. Then save them as `.csv`. - (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_df = pd.json_normalize(python['items'])\n",
    "ds_df = pd.json_normalize(data_science['items'])\n",
    "da_df = pd.json_normalize(data_analytics['items'])\n",
    "ml_df = pd.json_normalize(machine_learning['items'])\n",
    "dl_df = pd.json_normalize(deep_learning['items'])\n",
    "\n",
    "py_df.to_csv('python.csv')\n",
    "ds_df.to_csv('data_science.csv')\n",
    "da_df.to_csv('data_analytics.csv')\n",
    "ml_df.to_csv('machine_learning.csv')\n",
    "dl_df.to_csv('deep_learning.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) For each DataFrame, relabel `volumeInfo.title` as `Title` and `volumeInfo.authors` as `Authors`. - (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_df.rename(columns={'volumeInfo.title': 'Title', 'volumeInfo.authors': 'Authors'}, inplace=True)\n",
    "ds_df.rename(columns={'volumeInfo.title': 'Title', 'volumeInfo.authors': 'Authors'}, inplace=True)\n",
    "da_df.rename(columns={'volumeInfo.title': 'Title', 'volumeInfo.authors': 'Authors'}, inplace=True)\n",
    "ml_df.rename(columns={'volumeInfo.title': 'Title', 'volumeInfo.authors': 'Authors'}, inplace=True)\n",
    "dl_df.rename(columns={'volumeInfo.title': 'Title', 'volumeInfo.authors': 'Authors'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) For each DataFrame create a new column called `Topic` with the name of the topic from the API query above. Then merge all DataFrames into one and save it to a new `.csv` file. - (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_df[\"Topic\"] = \"Python\"\n",
    "ds_df[\"Topic\"] = \"Data Science\"\n",
    "da_df[\"Topic\"] = \"Data Analytics\"\n",
    "ml_df[\"Topic\"] = \"Machine Learning\"\n",
    "dl_df[\"Topic\"] = \"Deep Learning\"\n",
    "all_df = pd.concat([py_df, ds_df, da_df, ml_df, dl_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) Write a function that returns all rows whose `Title` contains the word `Data` (case incensitive). - (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_date(df):\n",
    "  df = df[df['Title'].str.contains('Data')]\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) Write a function that returns all rows whose `Authors` first or last name starts with the letter `E` - (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def authors(df):\n",
    "    authors = []\n",
    "    for i, row in df.iterrows():\n",
    "        name = row.values[6][0].split(\" \")\n",
    "        f_Name = name[0]\n",
    "        l_Name = name[-1]\n",
    "        if f_Name[0] == \"E\":\n",
    "          authors.append(row)\n",
    "        elif l_Name[0] == \"E\":\n",
    "          authors.append(row)\n",
    "    return authors\n",
    "    \n",
    "print(authors(all_df))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
